# Hoshikage v1.1.0 Implementation Plan & Prompts for AI Developer

## Overview
This document outlines the detailed implementation steps for adding **Diffusion LLM Support** to Hoshikage.
As an AI developer, you should follow these instructions step-by-step. Each step contains specific instructions and context.

---

## Prerequisite
Review the following documents to understand the full context:
1. `docs/v1.1.0_requirements.md` (Requirements & Parameter specs)
2. `docs/v1.1.0_system_design.md` (System Architecture & translated logic)

---

## Step 1: Update Configuration
**Goal**: Add Diffusion-specific parameters to `Config` struct and load them from env variables.

**Instruction**:
1. Open `src/config/settings.rs`.
2. Add the following fields to `Config` struct (use appropriate types):
   - `diffusion_steps`: i32 (default: 50)
   - `diffusion_algorithm`: i32 (default: 4) - Note: Store as integer in Config for simplicity, convert to Enum later.
   - `diffusion_schedule`: i32 (default: 0)
   - `diffusion_cfg_scale`: f32 (default: 0.0)
3. Update `Config::default()` to set these default values.
4. Update `Config::load()` to read these values from environment variables:
   - `DIFFUSION_STEPS` -> `diffusion_steps`
   - `DIFFUSION_ALGORITHM` -> `diffusion_algorithm`
   - `DIFFUSION_SCHEDULE` -> `diffusion_schedule`
   - `DIFFUSION_CFG_SCALE` -> `diffusion_cfg_scale`

---

## Step 2: Update FFI Bindings
**Goal**: Ensure `llama_model_is_diffusion` is available in `src/ffi.rs`.

**Instruction**:
1. Open `src/ffi.rs`.
2. Check if `llama_model_is_diffusion` is already defined (it likely isn't in the auto-generated bindings yet if the local llama.cpp is old).
3. If missing, manually add the signature at the bottom of the `extern "C"` block (or a new one):
   ```rust
   extern "C" {
       pub fn llama_model_is_diffusion(model: *const llama_model) -> bool;
   }
   ```
   *Note: Double check `src/inference/llama_wrapper.rs` to see if `LlamaModelIsDiffusion` type alias needs to be defined for dynamic loading.*

---

## Step 3: Implement Diffusion Logic in LlamaWrapper
**Goal**: Port the core diffusion generation loop from C++ to Rust. This is the most complex part.

**Instruction**:
1. Open `src/inference/llama_wrapper.rs`.
2. **Define Data Structures**:
   - Add `DiffusionAlgorithm` enum (Origin=0, EntropyBased=1, ...).
   - Add `TransferSchedule` enum (TimestepBased=0, BlockBased=1).
   - Add `DiffusionParams` struct with fields corresponding to Config + internal state.
3. **Define Helper Functions** (Ported from `diffusion-cli.cpp`):
   - `calculate_confidence(...) -> f32`
   - `calculate_transfer_count(...) -> i32`
   - `get_num_transfer_tokens(...) -> Vec<i32>` (if supporting BlockBased schedule)
   - `add_gumbel_noise(...)` (optional but recommended for completeness)
4. **Implement `generate_diffusion` method**:
   - Signature: `pub fn generate_diffusion(&self, prompt: &str, params: &DiffusionParams) -> Result<String>`
   - Logic:
     - **Tokenization**: Tokenize prompt.
     - **Initialization**: Create output buffer, fill prompt, fill rest with mask token.
     - **Main Loop**: Iterate `0..params.steps`:
       - Construct `llama_batch` for the current output tokens.
       - Call `llama_decode`.
       - Retrieve `logits`.
       - Apply sampling strategy (Confidence/Entropy) to decide which tokens to keep (unmask) and which to re-mask.
     - **Detokenization**: Convert final tokens to string.

---

## Step 4: Integrate Dispatch Logic
**Goal**: Automatically switch between AR and Diffusion generation.

**Instruction**:
1. Open `src/inference/llama_wrapper.rs`.
2. In `generate()` method:
   - Use `unsafe { llama_model_is_diffusion(self.model) }` to check model type. (You may need to load this symbol dynamically if not linked directly).
   - If `true`:
     - Construct `DiffusionParams` using values from `self.config` (you might need to pass `Config` to `generate` or store it in `LlamaWrapper`, or pass it via `InferenceParams` extensions).
     *Note: Currently `generate` takes `InferenceParams`. You might need to extend `InferenceParams` or mapping logic.*
     - Call `self.generate_diffusion(...)`.
   - If `false`:
     - Proceed with existing autoregressive generation.

---

## Step 5: Verification
**Goal**: Verify the implementation.

**Instruction**:
1. Run `cargo check` to ensure no compilation errors.
2. (Optional) Create a unit test in `src/inference/llama_wrapper.rs` (or a separate test file) that mocks the FFI calls if possible, or minimally checks that the code compiles and `DiffusionParams` defaults are correct.
