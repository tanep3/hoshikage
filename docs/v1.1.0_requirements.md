# Hoshikage v1.1.0 (Diffusion Support) Requirements

| ID | 機能 | 詳細 | 優先度 | ユースケース |
|----|------|------|--------|-------------|
| DLLM-001 | Diffusion LLM Inference | DiffusionベースのLLM (DLLMs, 例: LLaDA, Dream) の推論をサポートし、テキスト生成を可能にする。 | High | ユーザーが `diffusion_steps` 等を指定して高品質な生成を行う。 |
| DLLM-002 | API Compatibility | OpenAI互換API (`/v1/chat/completions`) において、Diffusionモデル指定時も透過的に動作させる。 | High | 既存のChat UIやクライアントからDLLMを利用する。 |
| DLLM-003 | Parameter Control | Diffusion特有のパラメータ (`steps`, `algorithm`, `guidance_scale` 等) を受け付ける仕組みを実装する。 | Medium | ユーザーが生成プロセスの詳細（速度 vs 品質のトレードオフ）を制御する。 |
| DLLM-004 | Memory Management | DLLM動作時のメモリ管理を最適化する（既存の静かなる知性システムとの整合性）。 | High | VRAM溢れを防ぎつつ、拡散ステップ実行中のメモリスパイクを制御する。 |

## Non-Functional Requirements (NFR)

| NFR-ID | カテゴリ | 要件 | 検証方法 |
|--------|----------|------|----------|
| PERF-010 | Latency | Diffusionモデルは自己回帰モデル(AR)より低速な傾向があるため、適切なタイムアウト設定と進捗フィードバックを検討する。 | 実測 (Tokens/s) |
| REL-010 | Compatibility | `llama.cpp` の最新DLLM実装を取り込み、既存のARモデル（Llama 3等）との共存における安定性を保証する。 | Regression Test |

## Technical Constraints & Notes
- **Library Base**: `llama.cpp` の diffusion branch または最新機能を使用。`examples/diffusion/diffusion-cli.cpp` を参考に Rust FFI (`ffi.rs`) とラッパー (`llama_wrapper.rs`) を拡張する。
- **Sampling**: Diffusionモデルは従来の `llama_sample_token_*` とは異なるサンプリングロジック（Diffusion Sampler）を持つ可能性があるため、C++側のロジックをRustで再実装するか、C++ヘルパー関数を追加する必要があるかもしれない。
- **Build**: `build.rs` は現在 `llama.h` / `ggml.h` のみを bindgen している。Diffusion 用の新しい定数や関数 (`llama_model_apply_diffusion` 等？) が必要か確認が必要。
- **Streaming**: Diffusionモデルは逐次生成に非対応のため、`stream=true` の場合は **疑似ストリーミング** として 1チャンクのみを返し、`[DONE]` で終了する。

## Parameter Configuration

Diffusionモデルはパラメータが多いため、ユーザー設定可能 (`.env`) なものと、内部固定/自動判定値を明確に分ける。

### ユーザー設定可能パラメータ (.env)
ユーザーが生成品質と速度のトレードオフを調整するためのパラメータ。

| パラメータ名 | 環境変数名 | デフォルト値 | 説明 |
|--------------|------------|--------------|------|
| Steps | `DIFFUSION_STEPS` | 50 | 拡散プロセスのステップ数。多いほど高品質だが遅い。 |
| Algorithm | `DIFFUSION_ALGORITHM` | `CONFIDENCE_BASED` (4) | サンプリングアルゴリズム (0:ORIGIN, 1:ENTROPY, 2:MARGIN, 3:RANDOM, 4:CONFIDENCE)。 |
| Schedule | `DIFFUSION_SCHEDULE` | `TIMESTEP_BASED` (0) | スケジューリング方式 (0:TIMESTEP_BASED, 1:BLOCK_BASED)。 |
| Guidance | `DIFFUSION_CFG_SCALE` | 0.0 | Classifier-Free Guidance スケール。0より大きい場合有効だが計算コスト増。 |

### 内部固定 / APIオーバーライド推奨パラメータ
これらは `.env` で固定するよりも、リクエスト毎に変更するか、モデルアーキテクチャ依存で決まるべきもの。

- `diffusion_visual` (Visual Mode): サーバー用途なので常に `false`。
- `mask_token_id`: モデルのVocabから自動取得 (`llama_vocab_mask`)。
- `shift_logits`: モデルのメタデータ (`diffusion.shift_logits`) から自動取得。
- `max_length` (`n_ubatch`): リクエストの `max_tokens` または `n_ctx` に従う。
- `top_p`, `top_k`, `temperature`: 既存の生成パラメータ (`TEMPERATURE`, `TOP_P`) を流用。
